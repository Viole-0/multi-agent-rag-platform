[
  {
    "text": "Recent work revealed a tension between the Gross-Mende analysis of the high-energy fixed-angle behavior of string amplitudes and the explicit numerical data. Motivated by this puzzle, we revisit the problem of classifying saddle-point geometries for the one-loop amplitude. We find an infinite family of complex saddles that dominate the high-energy regime. Using general constraints and matching to numerical data, we formulate a bootstrap problem that determines their multiplicities. This",
    "metadata": {
      "title": "Precision asymptotics of string amplitudes",
      "published": "2026-01-14 18:59:59+00:00"
    }
  },
  {
    "text": "to numerical data, we formulate a bootstrap problem that determines their multiplicities. This procedure yields a precise asymptotic expansion of the one-loop amplitude at high energies. The resulting oscillatory contributions lead to a much richer high-energy behavior than that predicted by the original Gross-Mende analysis.",
    "metadata": {
      "title": "Precision asymptotics of string amplitudes",
      "published": "2026-01-14 18:59:59+00:00"
    }
  },
  {
    "text": "Vision-Language-Action (VLA) tasks require reasoning over complex visual scenes and executing adaptive actions in dynamic environments. While recent studies on reasoning VLAs show that explicit chain-of-thought (CoT) can improve generalization, they suffer from high inference latency due to lengthy reasoning traces. We propose Fast-ThinkAct, an efficient reasoning framework that achieves compact yet performant planning through verbalizable latent reasoning. Fast-ThinkAct learns to reason",
    "metadata": {
      "title": "Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning",
      "published": "2026-01-14 18:59:59+00:00"
    }
  },
  {
    "text": "yet performant planning through verbalizable latent reasoning. Fast-ThinkAct learns to reason efficiently with latent CoTs by distilling from a teacher, driven by a preference-guided objective to align manipulation trajectories that transfers both linguistic and visual planning capabilities for embodied control. This enables reasoning-enhanced policy learning that effectively connects compact reasoning to action execution. Extensive experiments across diverse embodied manipulation and reasoning",
    "metadata": {
      "title": "Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning",
      "published": "2026-01-14 18:59:59+00:00"
    }
  },
  {
    "text": "to action execution. Extensive experiments across diverse embodied manipulation and reasoning benchmarks demonstrate that Fast-ThinkAct achieves strong performance with up to 89.3\\% reduced inference latency over state-of-the-art reasoning VLAs, while maintaining effective long-horizon planning, few-shot adaptation, and failure recovery.",
    "metadata": {
      "title": "Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning",
      "published": "2026-01-14 18:59:59+00:00"
    }
  },
  {
    "text": "Transformer-based language models often achieve strong results on mathematical reasoning benchmarks while remaining fragile on basic numerical understanding and arithmetic operations. A central limitation is that numbers are processed as symbolic tokens whose embeddings do not explicitly encode numerical value, leading to systematic errors. We introduce a value-aware numerical representation that augments standard tokenized inputs with a dedicated prefix token whose embedding is explicitly",
    "metadata": {
      "title": "Value-Aware Numerical Representations for Transformer Language Models",
      "published": "2026-01-14 18:59:14+00:00"
    }
  },
  {
    "text": "that augments standard tokenized inputs with a dedicated prefix token whose embedding is explicitly conditioned on the underlying numerical value. This mechanism injects magnitude information directly into the model's input space while remaining compatible with existing tokenizers and decoder-only Transformer architectures. Evaluation on arithmetic tasks shows that the proposed approach outperforms baselines across numerical formats, tasks, and operand lengths. These results indicate that",
    "metadata": {
      "title": "Value-Aware Numerical Representations for Transformer Language Models",
      "published": "2026-01-14 18:59:14+00:00"
    }
  },
  {
    "text": "baselines across numerical formats, tasks, and operand lengths. These results indicate that explicitly encoding numerical value is an effective and efficient way to improve fundamental numerical robustness in language models.",
    "metadata": {
      "title": "Value-Aware Numerical Representations for Transformer Language Models",
      "published": "2026-01-14 18:59:14+00:00"
    }
  },
  {
    "text": "Jahn--Teller (JT) distortions are a key driver of physical properties in many correlated oxide materials. Cooperative JT distortions, in which long-range orbital order reduces the symmetry of the average structure macroscopically, are common in JT-distorted materials at low temperatures. This long-range order will often melt on heating, \\textit{via} a transition to a high-temperature state without long-range orbital order. The nature of this transition has been observed to vary with different",
    "metadata": {
      "title": "Revisiting Jahn--Teller Transitions in Correlated Oxides with Monte Carlo Modeling",
      "published": "2026-01-14 18:58:36+00:00"
    }
  },
  {
    "text": "long-range orbital order. The nature of this transition has been observed to vary with different materials depending on crystal structure; in LaMnO$_3$ the transition has generally been interpreted as order-disorder, whereas in layered nickelates $A$NiO$_2$ ($A$=Li,Na) there is a displacive transition. Alternatively, recent theoretical work has suggested that previous attributions of order-disorder may in fact be a consequence of phonon anharmonicity, rather than persistence of JT distortions,",
    "metadata": {
      "title": "Revisiting Jahn--Teller Transitions in Correlated Oxides with Monte Carlo Modeling",
      "published": "2026-01-14 18:58:36+00:00"
    }
  },
  {
    "text": "may in fact be a consequence of phonon anharmonicity, rather than persistence of JT distortions, which would suggest that the displacive transition may be more common than currently believed. In this work, we run Monte Carlo simulations with a simple Hamiltonian which is modified to include terms dependent on the JT amplitude $\u03c1$, which is allowed to vary within the simulation \\textit{via} the Metropolis algorithm. Our simulations yield distributions of JT amplitudes consistent with displacive",
    "metadata": {
      "title": "Revisiting Jahn--Teller Transitions in Correlated Oxides with Monte Carlo Modeling",
      "published": "2026-01-14 18:58:36+00:00"
    }
  },
  {
    "text": "algorithm. Our simulations yield distributions of JT amplitudes consistent with displacive rather than order-disorder behaviour for both perovskites and layered nickelates, suggesting that displacive-like JT transitions may be more common than previously assumed in both perovskites and layered nickelates. We also find significant differences between the transition observed for perovskites compared with layered nickelates, which we attribute to differing extensivity of configurational entropy on",
    "metadata": {
      "title": "Revisiting Jahn--Teller Transitions in Correlated Oxides with Monte Carlo Modeling",
      "published": "2026-01-14 18:58:36+00:00"
    }
  },
  {
    "text": "with layered nickelates, which we attribute to differing extensivity of configurational entropy on the two lattices, showing the crucial role of lattice geometry in determining behaviour.",
    "metadata": {
      "title": "Revisiting Jahn--Teller Transitions in Correlated Oxides with Monte Carlo Modeling",
      "published": "2026-01-14 18:58:36+00:00"
    }
  },
  {
    "text": "We prove universality for cokernels of random integral matrices with symmetries via an approach different from the classical surjection moment method introduced by Wood (arXiv:1402.5149). In the symmetric case, we reprove Hodges' universality theorem (arXiv:2311.07078), i.e. the version incorporating the canonical pairing from Wood's setting, and in the alternating case we reprove the local universality theorem of Nguyen-Wood (arXiv:2210.08526). A key advantage of our method is that it is",
    "metadata": {
      "title": "Quantative universality for cokernels of matrices with symmetries",
      "published": "2026-01-14 18:58:05+00:00"
    }
  },
  {
    "text": "universality theorem of Nguyen-Wood (arXiv:2210.08526). A key advantage of our method is that it is quantitative: we obtain explicit error bounds, which are exponentially small in most regimes, thereby addressing Wood's question on effective convergence rates. Our argument is inspired by Maples' exposure-process and coupling viewpoint (arXiv:1301.1239) and uses a generalized form of Fourier-analytic estimates in the exponentially sharp style of Ferber-Jain-Sah-Sawhney (arXiv:2106.04049).",
    "metadata": {
      "title": "Quantative universality for cokernels of matrices with symmetries",
      "published": "2026-01-14 18:58:05+00:00"
    }
  },
  {
    "text": "Code generation tasks aim to automate the conversion of user requirements into executable code, significantly reducing manual development efforts and enhancing software productivity. The emergence of large language models (LLMs) has significantly advanced code generation, though their efficiency is still impacted by certain inherent architectural constraints. Each token generation necessitates a complete inference pass, requiring persistent retention of contextual information in memory and",
    "metadata": {
      "title": "ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation",
      "published": "2026-01-14 18:57:31+00:00"
    }
  },
  {
    "text": "a complete inference pass, requiring persistent retention of contextual information in memory and escalating resource consumption. While existing research prioritizes inference-phase optimizations such as prompt compression and model quantization, the generation phase remains underexplored. To tackle these challenges, we propose a knowledge-infused framework named ShortCoder, which optimizes code generation efficiency while preserving semantic equivalence and readability. In particular, we",
    "metadata": {
      "title": "ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation",
      "published": "2026-01-14 18:57:31+00:00"
    }
  },
  {
    "text": "code generation efficiency while preserving semantic equivalence and readability. In particular, we introduce: (1) ten syntax-level simplification rules for Python, derived from AST-preserving transformations, achieving 18.1% token reduction without functional compromise; (2) a hybrid data synthesis pipeline integrating rule-based rewriting with LLM-guided refinement, producing ShorterCodeBench, a corpus of validated tuples of original code and simplified code with semantic consistency; (3) a",
    "metadata": {
      "title": "ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation",
      "published": "2026-01-14 18:57:31+00:00"
    }
  },
  {
    "text": "a corpus of validated tuples of original code and simplified code with semantic consistency; (3) a fine-tuning strategy that injects conciseness awareness into the base LLMs. Extensive experimental results demonstrate that ShortCoder consistently outperforms state-of-the-art methods on HumanEval, achieving an improvement of 18.1%-37.8% in generation efficiency over previous methods while ensuring the performance of code generation.",
    "metadata": {
      "title": "ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation",
      "published": "2026-01-14 18:57:31+00:00"
    }
  },
  {
    "text": "Advanced metering infrastructure (AMI) provides high-resolution electricity consumption data that can enhance monitoring, diagnosis, and decision making in modern power distribution systems. Detecting anomalies in these time-series measurements is challenging due to nonlinear, nonstationary, and multi-scale temporal behavior across diverse building types and operating conditions. This work presents a systematic, power-system-oriented evaluation of a GAN-LSTM framework for smart meter anomaly",
    "metadata": {
      "title": "Evaluating GAN-LSTM for Smart Meter Anomaly Detection in Power Systems",
      "published": "2026-01-14 18:55:39+00:00"
    }
  },
  {
    "text": "a systematic, power-system-oriented evaluation of a GAN-LSTM framework for smart meter anomaly detection using the Large-scale Energy Anomaly Detection (LEAD) dataset, which contains one year of hourly measurements from 406 buildings. The proposed pipeline applies consistent preprocessing, temporal windowing, and threshold selection across all methods, and compares the GAN-LSTM approach against six widely used baselines, including statistical, kernel-based, reconstruction-based, and GAN-based",
    "metadata": {
      "title": "Evaluating GAN-LSTM for Smart Meter Anomaly Detection in Power Systems",
      "published": "2026-01-14 18:55:39+00:00"
    }
  },
  {
    "text": "six widely used baselines, including statistical, kernel-based, reconstruction-based, and GAN-based models. Experimental results demonstrate that the GAN-LSTM significantly improves detection performance, achieving an F1-score of 0.89. These findings highlight the potential of adversarial temporal modeling as a practical tool for supporting asset monitoring, non-technical loss detection, and situational awareness in real-world power distribution networks. The code for this work is publicly",
    "metadata": {
      "title": "Evaluating GAN-LSTM for Smart Meter Anomaly Detection in Power Systems",
      "published": "2026-01-14 18:55:39+00:00"
    }
  },
  {
    "text": "situational awareness in real-world power distribution networks. The code for this work is publicly available",
    "metadata": {
      "title": "Evaluating GAN-LSTM for Smart Meter Anomaly Detection in Power Systems",
      "published": "2026-01-14 18:55:39+00:00"
    }
  },
  {
    "text": "From the recent developing of nonlocal gradients with finite horizon $\u03b4>0$ based on general kernels, we introduce a new nonlocal $p$-Laplacian and study the eigenvalue problem associated with it. Furthermore, by virtue of $\u0393$-convergence arguments, we establish stability results of the solutions for varying horizon in the extreme cases $\u03b4\\to 0^+$ and $\u03b4\\to\\infty$, recovering the solutions for the local eigenvalue problem associated with the $p$-Laplacian, and the ones associated with the",
    "metadata": {
      "title": "Asymptotics of variational eigenvalues for a general nonlocal $p$-Laplacian with varying horizon",
      "published": "2026-01-14 18:54:54+00:00"
    }
  },
  {
    "text": "the local eigenvalue problem associated with the $p$-Laplacian, and the ones associated with the $H^{s,p}$-Laplacian, respectively.",
    "metadata": {
      "title": "Asymptotics of variational eigenvalues for a general nonlocal $p$-Laplacian with varying horizon",
      "published": "2026-01-14 18:54:54+00:00"
    }
  },
  {
    "text": "3D pose estimation from sparse multi-views is a critical task for numerous applications, including action recognition, sports analysis, and human-robot interaction. Optimization-based methods typically follow a two-stage pipeline, first detecting 2D keypoints in each view and then associating these detections across views to triangulate the 3D pose. Existing methods rely on mere pairwise associations to model this correspondence problem, treating global consistency between views (i.e., cycle",
    "metadata": {
      "title": "COMPOSE: Hypergraph Cover Optimization for Multi-view 3D Human Pose Estimation",
      "published": "2026-01-14 18:50:17+00:00"
    }
  },
  {
    "text": "to model this correspondence problem, treating global consistency between views (i.e., cycle consistency) as a soft constraint. Yet, reconciling these constraints for multiple views becomes brittle when spurious associations propagate errors. We thus propose COMPOSE, a novel framework that formulates multi-view pose correspondence matching as a hypergraph partitioning problem rather than through pairwise association. While the complexity of the resulting integer linear program grows",
    "metadata": {
      "title": "COMPOSE: Hypergraph Cover Optimization for Multi-view 3D Human Pose Estimation",
      "published": "2026-01-14 18:50:17+00:00"
    }
  },
  {
    "text": "through pairwise association. While the complexity of the resulting integer linear program grows exponentially in theory, we introduce an efficient geometric pruning strategy to substantially reduce the search space. COMPOSE achieves improvements of up to 23% in average precision over previous optimization-based methods and up to 11% over self-supervised end-to-end learned methods, offering a promising solution to a widely studied problem.",
    "metadata": {
      "title": "COMPOSE: Hypergraph Cover Optimization for Multi-view 3D Human Pose Estimation",
      "published": "2026-01-14 18:50:17+00:00"
    }
  },
  {
    "text": "Modern video generative models based on diffusion models can produce very realistic clips, but they are computationally inefficient, often requiring minutes of GPU time for just a few seconds of video. This inefficiency poses a critical barrier to deploying generative video in applications that require real-time interactions, such as embodied AI and VR/AR. This paper explores a new strategy for camera-conditioned video generation of static scenes: using diffusion-based generative models to",
    "metadata": {
      "title": "Efficient Camera-Controlled Video Generation of Static Scenes via Sparse Diffusion and 3D Rendering",
      "published": "2026-01-14 18:50:06+00:00"
    }
  },
  {
    "text": "camera-conditioned video generation of static scenes: using diffusion-based generative models to generate a sparse set of keyframes, and then synthesizing the full video through 3D reconstruction and rendering. By lifting keyframes into a 3D representation and rendering intermediate views, our approach amortizes the generation cost across hundreds of frames while enforcing geometric consistency. We further introduce a model that predicts the optimal number of keyframes for a given camera",
    "metadata": {
      "title": "Efficient Camera-Controlled Video Generation of Static Scenes via Sparse Diffusion and 3D Rendering",
      "published": "2026-01-14 18:50:06+00:00"
    }
  },
  {
    "text": "We further introduce a model that predicts the optimal number of keyframes for a given camera trajectory, allowing the system to adaptively allocate computation. Our final method, SRENDER, uses very sparse keyframes for simple trajectories and denser ones for complex camera motion. This results in video generation that is more than 40 times faster than the diffusion-based baseline in generating 20 seconds of video, while maintaining high visual fidelity and temporal stability, offering a",
    "metadata": {
      "title": "Efficient Camera-Controlled Video Generation of Static Scenes via Sparse Diffusion and 3D Rendering",
      "published": "2026-01-14 18:50:06+00:00"
    }
  },
  {
    "text": "20 seconds of video, while maintaining high visual fidelity and temporal stability, offering a practical path toward efficient and controllable video synthesis.",
    "metadata": {
      "title": "Efficient Camera-Controlled Video Generation of Static Scenes via Sparse Diffusion and 3D Rendering",
      "published": "2026-01-14 18:50:06+00:00"
    }
  },
  {
    "text": "LLMs are increasingly being integrated into clinical workflows, yet they often lack clinical empathy, an essential aspect of effective doctor-patient communication. Existing NLP frameworks focus on reactively labeling empathy in doctors' responses but offer limited support for anticipatory modeling of empathy needs, especially in general health queries. We introduce the Empathy Applicability Framework (EAF), a theory-driven approach that classifies patient queries in terms of the applicability",
    "metadata": {
      "title": "Empathy Applicability Modeling for General Health Queries",
      "published": "2026-01-14 18:47:02+00:00"
    }
  },
  {
    "text": "(EAF), a theory-driven approach that classifies patient queries in terms of the applicability of emotional reactions and interpretations, based on clinical, contextual, and linguistic cues. We release a benchmark of real patient queries, dual-annotated by Humans and GPT-4o. In the subset with human consensus, we also observe substantial human-GPT alignment. To validate EAF, we train classifiers on human-labeled and GPT-only annotations to predict empathy applicability, achieving strong",
    "metadata": {
      "title": "Empathy Applicability Modeling for General Health Queries",
      "published": "2026-01-14 18:47:02+00:00"
    }
  },
  {
    "text": "on human-labeled and GPT-only annotations to predict empathy applicability, achieving strong performance and outperforming the heuristic and zero-shot LLM baselines. Error analysis highlights persistent challenges: implicit distress, clinical-severity ambiguity, and contextual hardship, underscoring the need for multi-annotator modeling, clinician-in-the-loop calibration, and culturally diverse annotation. EAF provides a framework for identifying empathy needs before response generation,",
    "metadata": {
      "title": "Empathy Applicability Modeling for General Health Queries",
      "published": "2026-01-14 18:47:02+00:00"
    }
  },
  {
    "text": "annotation. EAF provides a framework for identifying empathy needs before response generation, establishes a benchmark for anticipatory empathy modeling, and enables supporting empathetic communication in asynchronous healthcare.",
    "metadata": {
      "title": "Empathy Applicability Modeling for General Health Queries",
      "published": "2026-01-14 18:47:02+00:00"
    }
  },
  {
    "text": "The rapid evolution of Large Language Models (LLMs) has strongly impacted software engineering, leading to a growing number of studies on automated unit test generation. However, the standalone use of LLMs without post-processing has proven insufficient, often producing tests that fail to compile or achieve high coverage. Several techniques have been proposed to address these issues, reporting improvements in test compilation and coverage. While important, LLM-based test generation techniques",
    "metadata": {
      "title": "How well LLM-based test generation techniques perform with newer LLM versions?",
      "published": "2026-01-14 18:46:32+00:00"
    }
  },
  {
    "text": "in test compilation and coverage. While important, LLM-based test generation techniques have been evaluated against relatively weak baselines (for todays' standards), i.e., old LLM versions and relatively weak prompts, which may exacerbate the performance contribution of the approaches. In other words, stronger (newer) LLMs may obviate any advantage these techniques bring. We investigate this issue by replicating four state-of-the-art LLM-based test generation tools, HITS, SymPrompt, TestSpark,",
    "metadata": {
      "title": "How well LLM-based test generation techniques perform with newer LLM versions?",
      "published": "2026-01-14 18:46:32+00:00"
    }
  },
  {
    "text": "by replicating four state-of-the-art LLM-based test generation tools, HITS, SymPrompt, TestSpark, and CoverUp that include engineering components aimed at guiding the test generation process through compilation and execution feedback, and evaluate their relative effectiveness and efficiency over a plain LLM test generation method. We integrate current LLM versions in all approaches and run an experiment on 393 classes and 3,657 methods. Our results show that the plain LLM approach can",
    "metadata": {
      "title": "How well LLM-based test generation techniques perform with newer LLM versions?",
      "published": "2026-01-14 18:46:32+00:00"
    }
  },
  {
    "text": "an experiment on 393 classes and 3,657 methods. Our results show that the plain LLM approach can outperform previous state-of-the-art approaches in all test effectiveness metrics we used: line coverage (by 17.72%), branch coverage (by 19.80%) and mutation score (by 20.92%), and it does so at a comparable cost (LLM queries). We also observe that the granularity at which the plain LLM is applied has a significant impact on the cost. We therefore propose targeting first the program classes, where",
    "metadata": {
      "title": "How well LLM-based test generation techniques perform with newer LLM versions?",
      "published": "2026-01-14 18:46:32+00:00"
    }
  },
  {
    "text": "a significant impact on the cost. We therefore propose targeting first the program classes, where test generation is more efficient, and then the uncovered methods to reduce the number of LLM requests. This strategy achieves comparable (slightly higher) effectiveness while requiring about 20% fewer LLM requests.",
    "metadata": {
      "title": "How well LLM-based test generation techniques perform with newer LLM versions?",
      "published": "2026-01-14 18:46:32+00:00"
    }
  },
  {
    "text": "As Large Language Models (LLMs) continue to scale, post-training pruning has emerged as a promising approach to reduce computational costs while preserving performance. Existing methods such as SparseGPT and Wanda achieve high sparsity through layer-wise weight reconstruction or activation-aware magnitude pruning, but rely on uniform or hand-crafted heuristics to determine per-layer sparsity ratios. Moreover, recent work has shown that pruned LLMs suffer from severe factual knowledge",
    "metadata": {
      "title": "LLMs can Compress LLMs: Adaptive Pruning by Agents",
      "published": "2026-01-14 18:45:36+00:00"
    }
  },
  {
    "text": "ratios. Moreover, recent work has shown that pruned LLMs suffer from severe factual knowledge degradation, with structured pruning methods experiencing near-total collapse in factual question-answering capabilities. We introduce agent-guided pruning, where a foundation model acts as an adaptive pruning agent to intelligently select which layers to prune at each iteration while preserving critical knowledge pathways. Our method constructs layer-wise sensitivity profiles by combining",
    "metadata": {
      "title": "LLMs can Compress LLMs: Adaptive Pruning by Agents",
      "published": "2026-01-14 18:45:36+00:00"
    }
  },
  {
    "text": "critical knowledge pathways. Our method constructs layer-wise sensitivity profiles by combining Wanda-inspired weight-activation metrics with gradient importance scores, normalized as z-scores for model-agnostic comparison. These statistics are processed by an LLM agent equipped with self-reflection capabilities, enabling it to learn from previous pruning outcomes and iteratively refine its strategy. A checkpoint rollback mechanism maintains model quality by reverting when perplexity",
    "metadata": {
      "title": "LLMs can Compress LLMs: Adaptive Pruning by Agents",
      "published": "2026-01-14 18:45:36+00:00"
    }
  },
  {
    "text": "its strategy. A checkpoint rollback mechanism maintains model quality by reverting when perplexity degradation exceeds a threshold. We evaluate our approach on Qwen3 models (4B and 8B parameters) at approximately 45% sparsity, demonstrating substantial improvements over structured pruning baselines: 56% relative improvement in MMLU accuracy, 19x better factual knowledge retention on FreebaseQA, and 69% lower perplexity degradation. Notably, our framework requires no retraining, operates in a",
    "metadata": {
      "title": "LLMs can Compress LLMs: Adaptive Pruning by Agents",
      "published": "2026-01-14 18:45:36+00:00"
    }
  },
  {
    "text": "and 69% lower perplexity degradation. Notably, our framework requires no retraining, operates in a model-agnostic manner, and exhibits effective self-correction with only 2-4 rollbacks across 21-40 iterations, demonstrating that foundation models can effectively guide the compression of other foundation models.",
    "metadata": {
      "title": "LLMs can Compress LLMs: Adaptive Pruning by Agents",
      "published": "2026-01-14 18:45:36+00:00"
    }
  },
  {
    "text": "Structure-based and ligand-based computational drug design have traditionally relied on disjoint data sources and modeling assumptions, limiting their joint use at scale. In this work, we introduce Contrastive Geometric Learning for Unified Computational Drug Design (ConGLUDe), a single contrastive geometric model that unifies structure- and ligand-based training. ConGLUDe couples a geometric protein encoder that produces whole-protein representations and implicit embeddings of predicted binding",
    "metadata": {
      "title": "Contrastive Geometric Learning Unlocks Unified Structure- and Ligand-Based Drug Design",
      "published": "2026-01-14 18:45:08+00:00"
    }
  },
  {
    "text": "encoder that produces whole-protein representations and implicit embeddings of predicted binding sites with a fast ligand encoder, removing the need for pre-defined pockets. By aligning ligands with both global protein representations and multiple candidate binding sites through contrastive learning, ConGLUDe supports ligand-conditioned pocket prediction in addition to virtual screening and target fishing, while being trained jointly on protein-ligand complexes and large-scale bioactivity data.",
    "metadata": {
      "title": "Contrastive Geometric Learning Unlocks Unified Structure- and Ligand-Based Drug Design",
      "published": "2026-01-14 18:45:08+00:00"
    }
  },
  {
    "text": "fishing, while being trained jointly on protein-ligand complexes and large-scale bioactivity data. Across diverse benchmarks, ConGLUDe achieves state-of-the-art zero-shot virtual screening performance in settings where no binding pocket information is provided as input, substantially outperforms existing methods on a challenging target fishing task, and demonstrates competitive ligand-conditioned pocket selection. These results highlight the advantages of unified structure-ligand training and",
    "metadata": {
      "title": "Contrastive Geometric Learning Unlocks Unified Structure- and Ligand-Based Drug Design",
      "published": "2026-01-14 18:45:08+00:00"
    }
  },
  {
    "text": "pocket selection. These results highlight the advantages of unified structure-ligand training and position ConGLUDe as a step toward general-purpose foundation models for drug discovery.",
    "metadata": {
      "title": "Contrastive Geometric Learning Unlocks Unified Structure- and Ligand-Based Drug Design",
      "published": "2026-01-14 18:45:08+00:00"
    }
  },
  {
    "text": "Large Language Model (LLM) routers dynamically select optimal models for given inputs. Existing approaches typically assume access to ground-truth labeled data, which is often unavailable in practice, especially when user request distributions are heterogeneous and unknown. We introduce Routing with Generated Data (RGD), a challenging setting in which routers are trained exclusively on generated queries and answers produced from high-level task descriptions by generator LLMs. We evaluate",
    "metadata": {
      "title": "Routing with Generated Data: Annotation-Free LLM Skill Estimation and Expert Selection",
      "published": "2026-01-14 18:43:32+00:00"
    }
  },
  {
    "text": "queries and answers produced from high-level task descriptions by generator LLMs. We evaluate query-answer routers (using both queries and labels) and query-only routers across four diverse benchmarks and 12 models, finding that query-answer routers degrade faster than query-only routers as generator quality decreases. Our analysis reveals two crucial characteristics of effective generators: they must accurately respond to their own questions, and their questions must produce sufficient",
    "metadata": {
      "title": "Routing with Generated Data: Annotation-Free LLM Skill Estimation and Expert Selection",
      "published": "2026-01-14 18:43:32+00:00"
    }
  },
  {
    "text": "they must accurately respond to their own questions, and their questions must produce sufficient performance differentiation among the model pool. We then show how filtering for these characteristics can improve the quality of generated data. We further propose CASCAL, a novel query-only router that estimates model correctness through consensus voting and identifies model-specific skill niches via hierarchical clustering. CASCAL is substantially more robust to generator quality, outperforming",
    "metadata": {
      "title": "Routing with Generated Data: Annotation-Free LLM Skill Estimation and Expert Selection",
      "published": "2026-01-14 18:43:32+00:00"
    }
  },
  {
    "text": "hierarchical clustering. CASCAL is substantially more robust to generator quality, outperforming the best query-answer router by 4.6% absolute accuracy when trained on weak generator data.",
    "metadata": {
      "title": "Routing with Generated Data: Annotation-Free LLM Skill Estimation and Expert Selection",
      "published": "2026-01-14 18:43:32+00:00"
    }
  },
  {
    "text": "Deep research systems are widely used for multi-step web research, analysis, and cross-source synthesis, yet their evaluation remains challenging. Existing benchmarks often require annotation-intensive task construction, rely on static evaluation dimensions, or fail to reliably verify facts when citations are missing. To bridge these gaps, we introduce DeepResearchEval, an automated framework for deep research task construction and agentic evaluation. For task construction, we propose a",
    "metadata": {
      "title": "DeepResearchEval: An Automated Framework for Deep Research Task Construction and Agentic Evaluation",
      "published": "2026-01-14 18:38:31+00:00"
    }
  },
  {
    "text": "for deep research task construction and agentic evaluation. For task construction, we propose a persona-driven pipeline generating realistic, complex research tasks anchored in diverse user profiles, applying a two-stage filter Task Qualification and Search Necessity to retain only tasks requiring multi-source evidence integration and external retrieval. For evaluation, we propose an agentic pipeline with two components: an Adaptive Point-wise Quality Evaluation that dynamically derives",
    "metadata": {
      "title": "DeepResearchEval: An Automated Framework for Deep Research Task Construction and Agentic Evaluation",
      "published": "2026-01-14 18:38:31+00:00"
    }
  },
  {
    "text": "pipeline with two components: an Adaptive Point-wise Quality Evaluation that dynamically derives task-specific evaluation dimensions, criteria, and weights conditioned on each generated task, and an Active Fact-Checking that autonomously extracts and verifies report statements via web search, even when citations are missing.",
    "metadata": {
      "title": "DeepResearchEval: An Automated Framework for Deep Research Task Construction and Agentic Evaluation",
      "published": "2026-01-14 18:38:31+00:00"
    }
  },
  {
    "text": "A recent STM experiment in 2D bilayer graphene [Y.-C. Tsui, et al., Nature 628, 287 (2024)], under a strong perpendicular magnetic field, has made a direct observation of the existence of three distinct filling-factor-dependent quantum phases in the lowest Landau level: the incompressible fractional quantum Hall liquid, a crystalline compressible hexagonal Wigner crystal with long-range order and rotational symmetry-breaking, and a random localized solid phase with no spatial order. We argue",
    "metadata": {
      "title": "Disorder-induced strong-field strong-localization in 2D systems",
      "published": "2026-01-14 18:38:20+00:00"
    }
  },
  {
    "text": "rotational symmetry-breaking, and a random localized solid phase with no spatial order. We argue that the spatially random localized phase at low filling is the recently proposed disorder-dominated strongly localized amorphous \"Anderson solid\" phase [A. Babber, et al., arXiv:2601.03521], which appears generically at a sample-dependent filling factor.",
    "metadata": {
      "title": "Disorder-induced strong-field strong-localization in 2D systems",
      "published": "2026-01-14 18:38:20+00:00"
    }
  },
  {
    "text": "The graphical Lasso (GLASSO) is a widely used algorithm for learning high-dimensional undirected Gaussian graphical models (GGM). Given i.i.d. observations from a multivariate normal distribution, GLASSO estimates the precision matrix by maximizing the log-likelihood with an \\ell_1-penalty on the off-diagonal entries. However, selecting an optimal regularization parameter \u03bbin this unsupervised setting remains a significant challenge. A well-known issue is that existing methods, such as",
    "metadata": {
      "title": "LARGE: A Locally Adaptive Regularization Approach for Estimating Gaussian Graphical Models",
      "published": "2026-01-14 18:37:50+00:00"
    }
  },
  {
    "text": "setting remains a significant challenge. A well-known issue is that existing methods, such as out-of-sample likelihood maximization, select a single global \u03bband do not account for heterogeneity in variable scaling or partial variances. Standardizing the data to unit variances, although a common workaround, has been shown to negatively affect graph recovery. Addressing the problem of nodewise adaptive tuning in graph estimation is crucial for applications like computational neuroscience, where",
    "metadata": {
      "title": "LARGE: A Locally Adaptive Regularization Approach for Estimating Gaussian Graphical Models",
      "published": "2026-01-14 18:37:50+00:00"
    }
  },
  {
    "text": "tuning in graph estimation is crucial for applications like computational neuroscience, where brain networks are constructed from highly heterogeneous, region-specific fMRI data.",
    "metadata": {
      "title": "LARGE: A Locally Adaptive Regularization Approach for Estimating Gaussian Graphical Models",
      "published": "2026-01-14 18:37:50+00:00"
    }
  },
  {
    "text": "In this work, we develop Locally Adaptive Regularization for Graph Estimation (LARGE), an approach to adaptively learn nodewise tuning parameters to improve graph estimation and selection. In each block coordinate descent step of GLASSO, we augment the nodewise Lasso regression to jointly estimate the regression coefficients and error variance, which in turn guides the adaptive learning of nodewise penalties. In simulations, LARGE consistently outperforms benchmark methods in graph recovery,",
    "metadata": {
      "title": "LARGE: A Locally Adaptive Regularization Approach for Estimating Gaussian Graphical Models",
      "published": "2026-01-14 18:37:50+00:00"
    }
  },
  {
    "text": "penalties. In simulations, LARGE consistently outperforms benchmark methods in graph recovery, demonstrates greater stability across replications, and achieves the best estimation accuracy in the most difficult simulation settings. We demonstrate the practical utility of our method by estimating brain functional connectivity from a real fMRI data set.",
    "metadata": {
      "title": "LARGE: A Locally Adaptive Regularization Approach for Estimating Gaussian Graphical Models",
      "published": "2026-01-14 18:37:50+00:00"
    }
  },
  {
    "text": "We introduce a category $\\mathsf{qGph}$ of quantum graphs, whose definition is motivated entirely from noncommutative geometry. For all quantum graphs $G$ and $H$ in $\\mathsf{qGph}$, we then construct a quantum graph $[G,H]$ of homomorphisms from $G$ to $H$, making $\\mathsf{qGph}$ a closed symmetric monoidal category. We prove that for all finite graphs $G$ and $H$, the quantum graph $[G,H]$ is nonempty iff the $(G,H)$-homomorphism game has a winning quantum strategy, directly generalizing the",
    "metadata": {
      "title": "Quantum graphs of homomorphisms",
      "published": "2026-01-14 18:36:43+00:00"
    }
  },
  {
    "text": "iff the $(G,H)$-homomorphism game has a winning quantum strategy, directly generalizing the classical case.",
    "metadata": {
      "title": "Quantum graphs of homomorphisms",
      "published": "2026-01-14 18:36:43+00:00"
    }
  },
  {
    "text": "The finite quantum graphs in $\\mathsf{qGph}$ are tracial, real, and self-adjoint, and the morphisms between them are CP morphisms that are adjoint to a unital $*$-homomorphism. We show that Weaver's two notions of a CP morphism coincide in this context. We also show that every finite reflexive quantum graph is the confusability quantum graph of a quantum channel, answering a question of Daws.",
    "metadata": {
      "title": "Quantum graphs of homomorphisms",
      "published": "2026-01-14 18:36:43+00:00"
    }
  },
  {
    "text": "Multi-Task Learning (MTL) combined with Low-Rank Adaptation (LoRA) has emerged as a promising direction for parameter-efficient deployment of Large Language Models (LLMs). By sharing a single adapter across multiple tasks, one can significantly reduce storage overhead. However, this approach suffers from negative transfer, where conflicting gradient updates from distinct tasks degrade the performance of individual tasks compared to single-task fine-tuning. This problem is exacerbated in LoRA due",
    "metadata": {
      "title": "Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection",
      "published": "2026-01-14 18:36:22+00:00"
    }
  },
  {
    "text": "of individual tasks compared to single-task fine-tuning. This problem is exacerbated in LoRA due to the low-rank constraint, which limits the optimization landscape's capacity to accommodate diverse task requirements. In this paper, we propose Ortho-LoRA, a gradient projection method specifically tailored for the bipartite structure of LoRA. Ortho-LoRA dynamically projects conflicting task gradients onto the orthogonal complement of each other within the intrinsic LoRA subspace. Extensive",
    "metadata": {
      "title": "Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection",
      "published": "2026-01-14 18:36:22+00:00"
    }
  },
  {
    "text": "onto the orthogonal complement of each other within the intrinsic LoRA subspace. Extensive experiments on the GLUE benchmark demonstrate that Ortho-LoRA effectively mitigates task interference, outperforming standard joint training and recovering 95\\% of the performance gap between multi-task and single-task baselines with negligible computational overhead.",
    "metadata": {
      "title": "Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection",
      "published": "2026-01-14 18:36:22+00:00"
    }
  },
  {
    "text": "We investigate heat transport in one-dimensional harmonic chains with mass disorder and weak bond disorder, coupled at both ends to oscillator heat baths through weak impedance mismatches. The model incorporates correlations in mass disorder, in bond disorder, and between the two. We find that the scaling of thermal conductivity $\u03ba$ with system size $N$ is determined solely by either mass disorder or bond disorder. This indicates that cross-correlations between the two types of disorder play no",
    "metadata": {
      "title": "Controlling thermal conductivity in harmonic chains with correlated mass and bond disorder: Analytical approach",
      "published": "2026-01-14 18:32:55+00:00"
    }
  },
  {
    "text": "or bond disorder. This indicates that cross-correlations between the two types of disorder play no important role in the scaling behavior of $\u03ba$. Consequently, by tuning the self-correlations, it is possible to control how the thermal conductivity scales with the system size. Such control could have potential applications in thermoelectric devices and thermal insulation technologies.",
    "metadata": {
      "title": "Controlling thermal conductivity in harmonic chains with correlated mass and bond disorder: Analytical approach",
      "published": "2026-01-14 18:32:55+00:00"
    }
  },
  {
    "text": "Recent analysis of 23 years of Hubble Space Telescope ACS/SBC data has shown that background levels can vary considerably between observations, with most filters showing over an order of magnitude variation. For the shorter-wavelength filters, the background is understood to be dominated by airglow; however, what precisely drives background variations is not well constrained for any filter. Here, we explore the causes of the background variation. Using over 8,000 archival SBC observations, we",
    "metadata": {
      "title": "Using 23 Years of ACS/SBC Data to Understand Backgrounds:Explaining & Predicting Background Variations",
      "published": "2026-01-14 18:31:06+00:00"
    }
  },
  {
    "text": "we explore the causes of the background variation. Using over 8,000 archival SBC observations, we developed a machine learning model that can accurately predict the background for an observation, based upon a set of 23 observational parameters. This model indicates that, depending on filter, the SBC background is generally dominated by Solar elevation, Solar separation angle, Earth limb angle of observation, SBC temperature, and target Galactic latitude.",
    "metadata": {
      "title": "Using 23 Years of ACS/SBC Data to Understand Backgrounds:Explaining & Predicting Background Variations",
      "published": "2026-01-14 18:31:06+00:00"
    }
  },
  {
    "text": "Consider the following puzzle: a farmland consists of several fields, each occupied by either a farmer, a fox, a chicken, or a caterpillar. Creatures in neighboring fields can swap positions as long as the fox avoids the farmer, the chicken avoids the fox, and the caterpillar avoids the chicken. The objective is to decide whether there exists a sequence of swaps that rearranges the creatures into a desired final configuration, while avoiding any unwanted encounters.",
    "metadata": {
      "title": "Complexity Thresholds for the Constrained Colored Token Swapping Problem",
      "published": "2026-01-14 18:30:04+00:00"
    }
  },
  {
    "text": "The above puzzle can be cast an instance of the \\emph{colored token swapping} problem with $k = 4$ colors (i.e., creature types), in which only certain pairs of colors can be swapped. We prove that such problem is $\\mathsf{PSPACE}$-hard even when the graph representing the farmland is planar and cubic. We also show that the problem is polynomial-time solvable when at most three creature types are involved. We do so by providing a more general algorithm deciding instances with arbitrary values",
    "metadata": {
      "title": "Complexity Thresholds for the Constrained Colored Token Swapping Problem",
      "published": "2026-01-14 18:30:04+00:00"
    }
  },
  {
    "text": "involved. We do so by providing a more general algorithm deciding instances with arbitrary values of $k$, as long as the set of all admissible swaps between creature types induces a \\emph{spanning star}.",
    "metadata": {
      "title": "Complexity Thresholds for the Constrained Colored Token Swapping Problem",
      "published": "2026-01-14 18:30:04+00:00"
    }
  },
  {
    "text": "Our results settle a problem explicitly left open in [Yang and Zhang, IPL 2025], which established $\\mathsf{PSPACE}$-completeness for eight creature types and left the complexity status unresolved when the number of creature types is between three and seven.",
    "metadata": {
      "title": "Complexity Thresholds for the Constrained Colored Token Swapping Problem",
      "published": "2026-01-14 18:30:04+00:00"
    }
  },
  {
    "text": "Modern supply chains are increasingly exposed to disruptions from geopolitical events, demand shocks, trade restrictions, to natural disasters. While many of these disruptions originate deep in the supply network, most companies still lack visibility beyond Tier-1 suppliers, leaving upstream vulnerabilities undetected until the impact cascades downstream. To overcome this blind-spot and move from reactive recovery to proactive resilience, we introduce a minimally supervised agentic AI framework",
    "metadata": {
      "title": "Automating Supply Chain Disruption Monitoring via an Agentic AI Approach",
      "published": "2026-01-14 18:28:31+00:00"
    }
  },
  {
    "text": "reactive recovery to proactive resilience, we introduce a minimally supervised agentic AI framework that autonomously monitors, analyses, and responds to disruptions across extended supply networks. The architecture comprises seven specialised agents powered by large language models and deterministic tools that jointly detect disruption signals from unstructured news, map them to multi-tier supplier networks, evaluate exposure based on network structure, and recommend mitigations such as",
    "metadata": {
      "title": "Automating Supply Chain Disruption Monitoring via an Agentic AI Approach",
      "published": "2026-01-14 18:28:31+00:00"
    }
  },
  {
    "text": "supplier networks, evaluate exposure based on network structure, and recommend mitigations such as alternative sourcing options. \\rev{We evaluate the framework across 30 synthesised scenarios covering three automotive manufacturers and five disruption classes. The system achieves high accuracy across core tasks, with F1 scores between 0.962 and 0.991, and performs full end-to-end analyses in a mean of 3.83 minutes at a cost of \\$0.0836 per disruption. Relative to industry benchmarks of",
    "metadata": {
      "title": "Automating Supply Chain Disruption Monitoring via an Agentic AI Approach",
      "published": "2026-01-14 18:28:31+00:00"
    }
  },
  {
    "text": "in a mean of 3.83 minutes at a cost of \\$0.0836 per disruption. Relative to industry benchmarks of multi-day, analyst-driven assessments, this represents a reduction of more than three orders of magnitude in response time. A real-world case study of the 2022 Russia-Ukraine conflict further demonstrates operational applicability. This work establishes a foundational step toward building resilient, proactive, and autonomous supply chains capable of managing disruptions across deep-tier networks.",
    "metadata": {
      "title": "Automating Supply Chain Disruption Monitoring via an Agentic AI Approach",
      "published": "2026-01-14 18:28:31+00:00"
    }
  },
  {
    "text": "The Courtade-Kumar conjecture posits that dictatorship functions maximize the mutual information between the function's output and a noisy version of its input over the Boolean hypercube. We present two significant advancements related to this conjecture. First, we resolve an open question posed by Courtade and Kumar, proving that for any Boolean function (regardless of bias), the sum of mutual information between the function's output and the individual noisy input coordinates is bounded by",
    "metadata": {
      "title": "Progress on the Courtade-Kumar Conjecture: Optimal High-Noise Entropy Bounds and Generalized Coordinate-wise Mutual Information",
      "published": "2026-01-14 18:23:18+00:00"
    }
  },
  {
    "text": "information between the function's output and the individual noisy input coordinates is bounded by $1-H(\u03b1)$, where $\u03b1$ is the noise parameter of the Binary Symmetric Channel. This generalizes their previous result which was restricted to balanced Boolean functions. Second, we advance the study of the main conjecture in the high noise regime. We establish an optimal error bound of $O(\u03bb^2)$ for the asymptotic entropy expansion, where $\u03bb= (1-2\u03b1)^2$, improving upon the previous best-known bounds.",
    "metadata": {
      "title": "Progress on the Courtade-Kumar Conjecture: Optimal High-Noise Entropy Bounds and Generalized Coordinate-wise Mutual Information",
      "published": "2026-01-14 18:23:18+00:00"
    }
  },
  {
    "text": "asymptotic entropy expansion, where $\u03bb= (1-2\u03b1)^2$, improving upon the previous best-known bounds. This refined analysis leads to a sharp, linear Fourier concentration bound for highly informative functions and significantly extends the range of the noise parameter $\u03bb$ for which the conjecture is proven to hold.",
    "metadata": {
      "title": "Progress on the Courtade-Kumar Conjecture: Optimal High-Noise Entropy Bounds and Generalized Coordinate-wise Mutual Information",
      "published": "2026-01-14 18:23:18+00:00"
    }
  },
  {
    "text": "GW231123 is an exceptional gravitational-wave event consistent with the merger of two massive, highly-spinning black holes. Reliable inference of the source properties is crucial for accurate interpretation of its astrophysical implications. However, characterization of GW231123 is challenging: only few signal cycles are observed and different signal models result in systematically different parameters. We investigate whether the interpretation of GW231123 is robust against model systematics and",
    "metadata": {
      "title": "The impact of waveform systematics and Gaussian noise on the interpretation of GW231123",
      "published": "2026-01-14 18:22:32+00:00"
    }
  },
  {
    "text": "We investigate whether the interpretation of GW231123 is robust against model systematics and Gaussian detector noise. We show that the model systematics observed in GW231123 can be reproduced for a simulated signal based on the numerical-relativity surrogate model NRSur7dq4. Simulating data using the maximum-likelihood NRSur7dq4 waveform for GW231123 and no noise realization, we closely recover the systematics observed for the real signal. We then explore how the headline properties of",
    "metadata": {
      "title": "The impact of waveform systematics and Gaussian noise on the interpretation of GW231123",
      "published": "2026-01-14 18:22:32+00:00"
    }
  },
  {
    "text": "the systematics observed for the real signal. We then explore how the headline properties of GW231123 are impacted by Gaussian detector noise. Using the NRSur7dq4 maximum-likelihood waveform and different noise realizations, we consistently find support for large masses, high spin magnitudes (median $\u03c7_1\\geq 0.7$), and high spin precession (median $\u03c7_\\mathrm{p}\\geq 0.68$). The spin in the direction of the angular momentum ($\u03c7_\\mathrm{eff}$) fluctuates more. Finally, again comparing to simulated",
    "metadata": {
      "title": "The impact of waveform systematics and Gaussian noise on the interpretation of GW231123",
      "published": "2026-01-14 18:22:32+00:00"
    }
  },
  {
    "text": "of the angular momentum ($\u03c7_\\mathrm{eff}$) fluctuates more. Finally, again comparing to simulated signals, we show that any differences in the GW231123 inference based on each separate detector are not statistically significant. These results show that the properties of GW231123, and most importantly the high mass and high spin magnitudes inferred by NRSur7dq4, are robust.",
    "metadata": {
      "title": "The impact of waveform systematics and Gaussian noise on the interpretation of GW231123",
      "published": "2026-01-14 18:22:32+00:00"
    }
  },
  {
    "text": "Blind image deconvolution refers to the problem of simultaneously estimating the blur kernel and the true image from a set of observations when both the blur kernel and the true image are unknown. Sometimes, additional image and/or blur information is available and the term semi-blind deconvolution (SBD) is used. We consider a recently introduced Bayesian conjugate hierarchical model for SBD, formulated on an extended cyclic lattice to allow a computationally scalable Gibbs sampler. In this",
    "metadata": {
      "title": "Bayesian Semi-Blind Deconvolution at Scale",
      "published": "2026-01-14 18:22:27+00:00"
    }
  },
  {
    "text": "formulated on an extended cyclic lattice to allow a computationally scalable Gibbs sampler. In this article, we extend this model to the general SBD problem, rewrite the previously proposed Gibbs sampler so that operations are performed in the Fourier domain whenever possible, and introduce a new marginal Hamiltonian Monte Carlo (HMC) blur update, obtained by analytically integrating the blur-image joint conditional over the image. The cyclic formulation combined with non-trivial linear algebra",
    "metadata": {
      "title": "Bayesian Semi-Blind Deconvolution at Scale",
      "published": "2026-01-14 18:22:27+00:00"
    }
  },
  {
    "text": "joint conditional over the image. The cyclic formulation combined with non-trivial linear algebra manipulations allows a Fourier-based, scalable HMC update, otherwise complicated by the rigid constraints of the SBD problem. Having determined the padding size in the cyclic embedding through a numerical experiment, we compare the mixing and exploration behaviour of the Gibbs and HMC blur updates on simulated data and on a real geophysical seismic imaging problem where we invert a grid with",
    "metadata": {
      "title": "Bayesian Semi-Blind Deconvolution at Scale",
      "published": "2026-01-14 18:22:27+00:00"
    }
  },
  {
    "text": "on simulated data and on a real geophysical seismic imaging problem where we invert a grid with $300\\times50$ nodes, corresponding to a posterior with approximately $80,000$ parameters.",
    "metadata": {
      "title": "Bayesian Semi-Blind Deconvolution at Scale",
      "published": "2026-01-14 18:22:27+00:00"
    }
  },
  {
    "text": "We examine the influence of a static dc electric field on Electromagnetically Induced Transparency (EIT) resonances that involve highly excited Rydberg states. Our focus is on how these resonances are altered when the relative orientation between the laser polarization and the external electric field vectors are varied. We experimentally demonstrate characteristic variations in the amplitude of the Stark-split EIT resonances, which can be explained by the selection rules in various geometries.",
    "metadata": {
      "title": "Static dc electric field orientation effects on two-photon Rydberg EIT",
      "published": "2026-01-14 18:19:45+00:00"
    }
  },
  {
    "text": "Stark-split EIT resonances, which can be explained by the selection rules in various geometries. We also present a simplified semi-analytical model that closely resembles the experimental observations. We use these findings to obtain information about the spatially inhomogeneous electric field, produced by a biased wire, using EIT fluorescence measurements that agrees with the expected angular dependencies. These results suggest that simultaneous analysis of frequency shifts and amplitudes of",
    "metadata": {
      "title": "Static dc electric field orientation effects on two-photon Rydberg EIT",
      "published": "2026-01-14 18:19:45+00:00"
    }
  },
  {
    "text": "These results suggest that simultaneous analysis of frequency shifts and amplitudes of Rydberg EIT resonances may enable vector electrometry of electrostatic fields, necessary for many quantum sensing applications.",
    "metadata": {
      "title": "Static dc electric field orientation effects on two-photon Rydberg EIT",
      "published": "2026-01-14 18:19:45+00:00"
    }
  },
  {
    "text": "Designing large coupling memory quasi-cyclic spatially-coupled LDPC (QC-SC-LDPC) codes with low error floors requires eliminating specific harmful substructures (e.g., short cycles) induced by edge spreading and lifting. Building on our work~\\cite{r15} that introduced a Clique Lov\u00e1sz Local Lemma (CLLL)-based design principle and a Moser--Tardos (MT)-type constructive approach, this work quantifies the size and structure of the feasible design space. Using the quantitative CLLL, we derive",
    "metadata": {
      "title": "Counting and Entropy Bounds for Structure-Avoiding Spatially-Coupled LDPC Constructions",
      "published": "2026-01-14 18:15:46+00:00"
    }
  },
  {
    "text": "the size and structure of the feasible design space. Using the quantitative CLLL, we derive explicit lower bounds on the number of partition matrices satisfying a given family of structure-avoidance constraints, and further obtain bounds on the number of non-equivalent solutions under row/column permutations. Moreover, via R\u00e9nyi-entropy bounds for the MT distribution, we provide a computable lower bound on the number of distinct solutions that the MT algorithm can output, giving a concrete",
    "metadata": {
      "title": "Counting and Entropy Bounds for Structure-Avoiding Spatially-Coupled LDPC Constructions",
      "published": "2026-01-14 18:15:46+00:00"
    }
  },
  {
    "text": "lower bound on the number of distinct solutions that the MT algorithm can output, giving a concrete diversity guarantee for randomized constructions. Specializations for eliminating 4-cycle candidates yield closed-form bounds as functions of system parameters, offering a principled way to size memory/lifting and to estimate the remaining search space.",
    "metadata": {
      "title": "Counting and Entropy Bounds for Structure-Avoiding Spatially-Coupled LDPC Constructions",
      "published": "2026-01-14 18:15:46+00:00"
    }
  },
  {
    "text": "Existing match classification models in the tournament design literature have two major limitations: a contestant is considered indifferent only if uncertain future results do never affect its prize, and competitive matches are not distinguished with respect to the incentives of the contestants. We propose a probabilistic framework to address both issues. For each match, our approach relies on simulating all other matches played simultaneously or later to compute the qualifying probabilities",
    "metadata": {
      "title": "A probabilistic match classification model for sports tournaments",
      "published": "2026-01-14 18:15:32+00:00"
    }
  },
  {
    "text": "simulating all other matches played simultaneously or later to compute the qualifying probabilities under the three main outcomes (win, draw, loss), which allows the classification of each match into six different categories. The suggested model is applied to the previous group stage and the new incomplete round-robin league, introduced in the 2024/25 season of UEFA club competitions. An incomplete round-robin tournament is found to contain fewer stakeless matches where both contestants are",
    "metadata": {
      "title": "A probabilistic match classification model for sports tournaments",
      "published": "2026-01-14 18:15:32+00:00"
    }
  },
  {
    "text": "round-robin tournament is found to contain fewer stakeless matches where both contestants are indifferent, and substantially more matches where both contestants should play offensively. However, the robustly higher proportion of potentially collusive matches can threaten with serious scandals.",
    "metadata": {
      "title": "A probabilistic match classification model for sports tournaments",
      "published": "2026-01-14 18:15:32+00:00"
    }
  },
  {
    "text": "The generation of non-Gaussian quantum states is a key requirement for universal continuous-variable quantum information processing. We report the experimental generation of large-amplitude squeezed coherent-state superpositions (squeezed cat states) on free-space optical pulses, reaching an amplitude of $\u03b1= 2.47$, which, to our knowledge, exceeds all previously reported values. Our protocol relies on the controlled mixing of the Fock states $|1\\rangle$ and $|2\\rangle$ through a tunable beam",
    "metadata": {
      "title": "Generation of Large Coherent-State Superpositions in Free-Space Optical Pulses",
      "published": "2026-01-14 18:12:43+00:00"
    }
  },
  {
    "text": "on the controlled mixing of the Fock states $|1\\rangle$ and $|2\\rangle$ through a tunable beam splitter, followed by heralding via homodyne detection. The resulting state displays three well-resolved negative regions in its Wigner function and achieves a fidelity of $0.53$ with the target state $\\propto \\hat{S}(z)(|\u03b1\\rangle - |-\u03b1\\rangle)$, with $\u03b1= 2.47$ and squeezing parameter $z = 0.56$. These results constitute a significant milestone for temporal breeding protocols and for the iterative",
    "metadata": {
      "title": "Generation of Large Coherent-State Superpositions in Free-Space Optical Pulses",
      "published": "2026-01-14 18:12:43+00:00"
    }
  },
  {
    "text": "results constitute a significant milestone for temporal breeding protocols and for the iterative generation of optical GKP states, opening new perspectives for scalable and fault-tolerant photonic quantum architectures.",
    "metadata": {
      "title": "Generation of Large Coherent-State Superpositions in Free-Space Optical Pulses",
      "published": "2026-01-14 18:12:43+00:00"
    }
  },
  {
    "text": "We present STEP3-VL-10B, a lightweight open-source foundation model designed to redefine the trade-off between compact efficiency and frontier-level multimodal intelligence. STEP3-VL-10B is realized through two strategic shifts: first, a unified, fully unfrozen pre-training strategy on 1.2T multimodal tokens that integrates a language-aligned Perception Encoder with a Qwen3-8B decoder to establish intrinsic vision-language synergy; and second, a scaled post-training pipeline featuring over 1k",
    "metadata": {
      "title": "STEP3-VL-10B Technical Report",
      "published": "2026-01-14 17:58:24+00:00"
    }
  },
  {
    "text": "intrinsic vision-language synergy; and second, a scaled post-training pipeline featuring over 1k iterations of reinforcement learning. Crucially, we implement Parallel Coordinated Reasoning (PaCoRe) to scale test-time compute, allocating resources to scalable perceptual reasoning that explores and synthesizes diverse visual hypotheses. Consequently, despite its compact 10B footprint, STEP3-VL-10B rivals or surpasses models 10$\\times$-20$\\times$ larger (e.g., GLM-4.6V-106B, Qwen3-VL-235B) and",
    "metadata": {
      "title": "STEP3-VL-10B Technical Report",
      "published": "2026-01-14 17:58:24+00:00"
    }
  },
  {
    "text": "rivals or surpasses models 10$\\times$-20$\\times$ larger (e.g., GLM-4.6V-106B, Qwen3-VL-235B) and top-tier proprietary flagships like Gemini 2.5 Pro and Seed-1.5-VL. Delivering best-in-class performance, it records 92.2% on MMBench and 80.11% on MMMU, while excelling in complex reasoning with 94.43% on AIME2025 and 75.95% on MathVision. We release the full model suite to provide the community with a powerful, efficient, and reproducible baseline.",
    "metadata": {
      "title": "STEP3-VL-10B Technical Report",
      "published": "2026-01-14 17:58:24+00:00"
    }
  },
  {
    "text": "Multi-agent systems have evolved into practical LLM-driven collaborators for many applications, gaining robustness from diversity and cross-checking. However, multi-agent RL (MARL) training is resource-intensive and unstable: co-adapting teammates induce non-stationarity, and rewards are often sparse and high-variance. Therefore, we introduce \\textbf{Multi-Agent Test-Time Reinforcement Learning (MATTRL)}, a framework that injects structured textual experience into multi-agent deliberation at",
    "metadata": {
      "title": "Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning",
      "published": "2026-01-14 17:57:43+00:00"
    }
  },
  {
    "text": "(MATTRL)}, a framework that injects structured textual experience into multi-agent deliberation at inference time. MATTRL forms a multi-expert team of specialists for multi-turn discussions, retrieves and integrates test-time experiences, and reaches consensus for final decision-making. We also study credit assignment for constructing a turn-level experience pool, then reinjecting it into the dialogue. Across challenging benchmarks in medicine, math, and education, MATTRL improves accuracy by",
    "metadata": {
      "title": "Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning",
      "published": "2026-01-14 17:57:43+00:00"
    }
  },
  {
    "text": "Across challenging benchmarks in medicine, math, and education, MATTRL improves accuracy by an average of 3.67\\% over a multi-agent baseline, and by 8.67\\% over comparable single-agent baselines. Ablation studies examine different credit-assignment schemes and provide a detailed comparison of how they affect training outcomes. MATTRL offers a stable, effective and efficient path to distribution-shift-robust multi-agent reasoning without tuning.",
    "metadata": {
      "title": "Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning",
      "published": "2026-01-14 17:57:43+00:00"
    }
  },
  {
    "text": "Monocular visual SLAM enables 3D reconstruction from internet video and autonomous navigation on resource-constrained platforms, yet suffers from scale drift, i.e., the gradual divergence of estimated scale over long sequences. Existing frame-to-frame methods achieve real-time performance through local optimization but accumulate scale drift due to the lack of global constraints among independent windows. To address this, we propose SCE-SLAM, an end-to-end SLAM system that maintains scale",
    "metadata": {
      "title": "SCE-SLAM: Scale-Consistent Monocular SLAM via Scene Coordinate Embeddings",
      "published": "2026-01-14 17:57:08+00:00"
    }
  },
  {
    "text": "windows. To address this, we propose SCE-SLAM, an end-to-end SLAM system that maintains scale consistency through scene coordinate embeddings, which are learned patch-level representations encoding 3D geometric relationships under a canonical scale reference. The framework consists of two key modules: geometry-guided aggregation that leverages 3D spatial proximity to propagate scale information from historical observations through geometry-modulated attention, and scene coordinate bundle",
    "metadata": {
      "title": "SCE-SLAM: Scale-Consistent Monocular SLAM via Scene Coordinate Embeddings",
      "published": "2026-01-14 17:57:08+00:00"
    }
  },
  {
    "text": "from historical observations through geometry-modulated attention, and scene coordinate bundle adjustment that anchors current estimates to the reference scale through explicit 3D coordinate constraints decoded from the scene coordinate embeddings. Experiments on KITTI, Waymo, and vKITTI demonstrate substantial improvements: our method reduces absolute trajectory error by 8.36m on KITTI compared to the best prior approach, while maintaining 36 FPS and achieving scale consistency across",
    "metadata": {
      "title": "SCE-SLAM: Scale-Consistent Monocular SLAM via Scene Coordinate Embeddings",
      "published": "2026-01-14 17:57:08+00:00"
    }
  },
  {
    "text": "to the best prior approach, while maintaining 36 FPS and achieving scale consistency across large-scale scenes.",
    "metadata": {
      "title": "SCE-SLAM: Scale-Consistent Monocular SLAM via Scene Coordinate Embeddings",
      "published": "2026-01-14 17:57:08+00:00"
    }
  },
  {
    "text": "In this paper, we explore the inflationary dynamics of the $\u03b2$-exponential potential model, where a scalar field couples to quadratic $(R + R^2)$ gravity. In this model, the inflaton is the field that determines the size of the extra dimension. We employ the Palatini formalism to derive the resulting Einstein-frame generalized $k$-inflation effective theory, which we analyze under the assumption that the constant-roll condition is satisfied.",
    "metadata": {
      "title": "Constant-roll $\u03b2$-exponential inflation: Palatini formalism",
      "published": "2026-01-14 17:55:56+00:00"
    }
  },
  {
    "text": "We scan the parameter space for inflationary predictions, specifically the spectral index $n_s$ and the tensor-to-scalar ratio $r$, ensuring consistency with the results from ACT DR6. The compliant regions are depicted accordingly. For a suitable range of the model parameters, the values obtained for the inflationary observables align with the most recent observations by the Atacama Cosmology Telescope (ACT) collaboration and/or the Planck mission.",
    "metadata": {
      "title": "Constant-roll $\u03b2$-exponential inflation: Palatini formalism",
      "published": "2026-01-14 17:55:56+00:00"
    }
  },
  {
    "text": "Identifying individual animals in long-duration videos is essential for behavioral ecology, wildlife monitoring, and livestock management. Traditional methods require extensive manual annotation, while existing self-supervised approaches are computationally demanding and ill-suited for long sequences due to memory constraints and temporal error propagation. We introduce a highly efficient, self-supervised method that reframes animal identification as a global clustering task rather than a",
    "metadata": {
      "title": "Self-Supervised Animal Identification for Long Videos",
      "published": "2026-01-14 17:53:59+00:00"
    }
  },
  {
    "text": "method that reframes animal identification as a global clustering task rather than a sequential tracking problem. Our approach assumes a known, fixed number of individuals within a single video -- a common scenario in practice -- and requires only bounding box detections and the total count. By sampling pairs of frames, using a frozen pre-trained backbone, and employing a self-bootstrapping mechanism with the Hungarian algorithm for in-batch pseudo-label assignment, our method learns",
    "metadata": {
      "title": "Self-Supervised Animal Identification for Long Videos",
      "published": "2026-01-14 17:53:59+00:00"
    }
  },
  {
    "text": "mechanism with the Hungarian algorithm for in-batch pseudo-label assignment, our method learns discriminative features without identity labels. We adapt a Binary Cross Entropy loss from vision-language models, enabling state-of-the-art accuracy ($>$97\\%) while consuming less than 1 GB of GPU memory per batch -- an order of magnitude less than standard contrastive methods. Evaluated on challenging real-world datasets (3D-POP pigeons and 8-calves feeding videos), our framework matches or",
    "metadata": {
      "title": "Self-Supervised Animal Identification for Long Videos",
      "published": "2026-01-14 17:53:59+00:00"
    }
  },
  {
    "text": "real-world datasets (3D-POP pigeons and 8-calves feeding videos), our framework matches or surpasses supervised baselines trained on over 1,000 labeled frames, effectively removing the manual annotation bottleneck. This work enables practical, high-accuracy animal identification on consumer-grade hardware, with broad applicability in resource-constrained research settings. All code written for this paper are \\href{https://huggingface.co/datasets/tonyFang04/8-calves}{here}.",
    "metadata": {
      "title": "Self-Supervised Animal Identification for Long Videos",
      "published": "2026-01-14 17:53:59+00:00"
    }
  },
  {
    "text": "Large-scale vision-language models such as CLIP achieve strong zero-shot recognition but struggle with classes that are rarely seen during pretraining, including newly emerging entities and culturally specific categories. We introduce LiteEmbed, a lightweight framework for few-shot personalization of CLIP that enables new classes to be added without retraining its encoders. LiteEmbed performs subspace-guided optimization of text embeddings within CLIP's vocabulary, leveraging a PCA-based",
    "metadata": {
      "title": "LiteEmbed: Adapting CLIP to Rare Classes",
      "published": "2026-01-14 17:53:11+00:00"
    }
  },
  {
    "text": "subspace-guided optimization of text embeddings within CLIP's vocabulary, leveraging a PCA-based decomposition that disentangles coarse semantic directions from fine-grained variations. Two complementary objectives, coarse alignment and fine separation, jointly preserve global semantic consistency while enhancing discriminability among visually similar classes. Once optimized, the embeddings are plug-and-play, seamlessly substituting CLIP's original text features across classification,",
    "metadata": {
      "title": "LiteEmbed: Adapting CLIP to Rare Classes",
      "published": "2026-01-14 17:53:11+00:00"
    }
  },
  {
    "text": "are plug-and-play, seamlessly substituting CLIP's original text features across classification, retrieval, segmentation, and detection tasks. Extensive experiments demonstrate substantial gains over prior methods, establishing LiteEmbed as an effective approach for adapting CLIP to underrepresented, rare, or unseen classes.",
    "metadata": {
      "title": "LiteEmbed: Adapting CLIP to Rare Classes",
      "published": "2026-01-14 17:53:11+00:00"
    }
  },
  {
    "text": "In this work, we characterized the material properties of an animal model of the rotator cuff tendon using full volume datasets of both its intact and injured states by capturing internal strain behavior throughout the tendon. Our experimental setup, involving tension along the fiber direction, activated volumetric, tensile, and shear mechanisms due to the tendon's complex geometry. We implemented an approach to model inference that we refer to as variational system identification (VSI) to solve",
    "metadata": {
      "title": "Constitutive parameter inference using physics-based data-driven modeling in full volume datasets of intact and torn rotator cuff tendons",
      "published": "2026-01-14 17:51:44+00:00"
    }
  },
  {
    "text": "an approach to model inference that we refer to as variational system identification (VSI) to solve the weak form of the stress equilibrium equation using these full volume displacements. Three constitutive models were used for parameter inference: a neo-Hookean model, a modified Holzapfel-Gasser-Ogden (HGO) model with higher-order terms in the first and second invariants, and a reduced polynomial model consisting of terms based on the first, second, and fiber-related invariants. Inferred",
    "metadata": {
      "title": "Constitutive parameter inference using physics-based data-driven modeling in full volume datasets of intact and torn rotator cuff tendons",
      "published": "2026-01-14 17:51:44+00:00"
    }
  },
  {
    "text": "model consisting of terms based on the first, second, and fiber-related invariants. Inferred parameters were further refined using an adjoint-based partial differential equation (PDE)-constrained optimization framework. Our results show that the modified HGO model captures the tendon's deformation mechanisms with reasonable accuracy, while the neo-Hookean model fails to reproduce key internal features, particularly the shear behavior in the injured tendon. Surprisingly, the simplified",
    "metadata": {
      "title": "Constitutive parameter inference using physics-based data-driven modeling in full volume datasets of intact and torn rotator cuff tendons",
      "published": "2026-01-14 17:51:44+00:00"
    }
  },
  {
    "text": "features, particularly the shear behavior in the injured tendon. Surprisingly, the simplified polynomial model performed comparably to the modified HGO formulation using only three terms. These findings suggest that while current constitutive models do not fully replicate the complex internal mechanics of the tendon, they are capable of capturing key trends in both intact and damaged tissue, using a homogeneous modeling approach. Continued model development is needed to bridge this gap and",
    "metadata": {
      "title": "Constitutive parameter inference using physics-based data-driven modeling in full volume datasets of intact and torn rotator cuff tendons",
      "published": "2026-01-14 17:51:44+00:00"
    }
  },
  {
    "text": "using a homogeneous modeling approach. Continued model development is needed to bridge this gap and enable clinical-grade, predictive simulations of tendon injury and repair.",
    "metadata": {
      "title": "Constitutive parameter inference using physics-based data-driven modeling in full volume datasets of intact and torn rotator cuff tendons",
      "published": "2026-01-14 17:51:44+00:00"
    }
  },
  {
    "text": "While Kolmogorov's probability axioms are widely recognized, it is less well known that in an often-overlooked 1930 note, Kolmogorov proposed an axiomatic framework for a unifying concept of the mean -- referred to as regular means. This framework yields a well-defined functional form encompassing the arithmetic, geometric, and harmonic means, among others.",
    "metadata": {
      "title": "On the Kolmogorov Superposition Theorem and Regular Means",
      "published": "2026-01-14 17:50:01+00:00"
    }
  },
  {
    "text": "In this article, we uncover an elegant connection between two key results of Kolmogorov by showing that the class of regular means can be derived directly from the Kolmogorov superposition theorem. This connection is conceptually appealing and illustrates that the superposition theorem deserves wider recognition in Statistics -- not only because of its link to regular means as shown here, but also due to its influence on the development of neural models and its potential connections with",
    "metadata": {
      "title": "On the Kolmogorov Superposition Theorem and Regular Means",
      "published": "2026-01-14 17:50:01+00:00"
    }
  },
  {
    "text": "also due to its influence on the development of neural models and its potential connections with other statistical frameworks. In addition, we establish a stability property of regular means, showing that they vary smoothly under small perturbations of the generator. Finally, we provide insights into a recent universal central limit theorem that applies to the broad class of regular means.",
    "metadata": {
      "title": "On the Kolmogorov Superposition Theorem and Regular Means",
      "published": "2026-01-14 17:50:01+00:00"
    }
  },
  {
    "text": "Estimating physically accurate, simulation-ready garments from a single image is challenging due to the absence of image-to-physics datasets and the ill-posed nature of this problem. Prior methods either require multi-view capture and expensive differentiable simulation or predict only garment geometry without the material properties required for realistic simulation. We propose a feed-forward framework that sidesteps these limitations by first fine-tuning a vision-language model to infer",
    "metadata": {
      "title": "Image2Garment: Simulation-ready Garment Generation from a Single Image",
      "published": "2026-01-14 17:47:33+00:00"
    }
  },
  {
    "text": "framework that sidesteps these limitations by first fine-tuning a vision-language model to infer material composition and fabric attributes from real images, and then training a lightweight predictor that maps these attributes to the corresponding physical fabric parameters using a small dataset of material-physics measurements. Our approach introduces two new datasets (FTAG and T2P) and delivers simulation-ready garments from a single image without iterative optimization. Experiments show that",
    "metadata": {
      "title": "Image2Garment: Simulation-ready Garment Generation from a Single Image",
      "published": "2026-01-14 17:47:33+00:00"
    }
  },
  {
    "text": "simulation-ready garments from a single image without iterative optimization. Experiments show that our estimator achieves superior accuracy in material composition estimation and fabric attribute prediction, and by passing them through our physics parameter estimator, we further achieve higher-fidelity simulations compared to state-of-the-art image-to-garment methods.",
    "metadata": {
      "title": "Image2Garment: Simulation-ready Garment Generation from a Single Image",
      "published": "2026-01-14 17:47:33+00:00"
    }
  },
  {
    "text": "For a model convection-diffusion problem, we address the presence of oscillatory discrete solutions, and study difficulties in recovering standard approximation results for its solution. We justify the presence of non-physical oscillations and propose ways to eliminate oscillations. A new approach for error analysis that requires establishing optimal discrete infinity error as a first step is introduced and justified. We emphasize that the discretization of two dimensional convection dominated",
    "metadata": {
      "title": "Explaining oscillatory behavior in convection-diffusion discretization",
      "published": "2026-01-14 17:47:14+00:00"
    }
  },
  {
    "text": "and justified. We emphasize that the discretization of two dimensional convection dominated problems benefit from the efficient discretization of the corresponding one dimensional problem along each stream line. Our results are useful in building new and robust discretizations for multi-dimensional convection dominated problems.",
    "metadata": {
      "title": "Explaining oscillatory behavior in convection-diffusion discretization",
      "published": "2026-01-14 17:47:14+00:00"
    }
  },
  {
    "text": "We present a closed-form surrogate for the equivalent diameter of the Kerr black-hole shadow, defined as the diameter of the circle with the same area as the shadow's critical curve. The construction enforces the exact face-on (polar) limit by explicitly separating an analytically computed polar contribution based on the spherical photon-orbit branch where the horizontal impact parameter vanishes. The remaining inclination dependence is captured by a compact 15-parameter polynomial placed inside",
    "metadata": {
      "title": "A Closed-Form Surrogate for the Equivalent Diameter of the Kerr Shadow",
      "published": "2026-01-14 17:44:54+00:00"
    }
  },
  {
    "text": "The remaining inclination dependence is captured by a compact 15-parameter polynomial placed inside an exponential correction. The coefficients are determined by ordinary least squares on a deterministic reference grid generated from the Kerr critical-curve area. Over the practical domain of dimensionless spin from 0 to 0.998 and inclination from just above 0 degrees up to 90 degrees (with the exactly polar point treated analytically), the surrogate achieves sub-percent accuracy. On the",
    "metadata": {
      "title": "A Closed-Form Surrogate for the Equivalent Diameter of the Kerr Shadow",
      "published": "2026-01-14 17:44:54+00:00"
    }
  },
  {
    "text": "the exactly polar point treated analytically), the surrogate achieves sub-percent accuracy. On the training grid the median absolute percent error is 0.0105 percent with a worst case of 0.782 percent, and on a denser out-of-sample validation set (including inclinations down to 0.5 degrees) the median, 95th-percentile, and worst-case errors are 0.023 percent, 0.471 percent, and 1.64 percent, respectively. The resulting expression provides fast evaluations of the shadow size without numerical ray",
    "metadata": {
      "title": "A Closed-Form Surrogate for the Equivalent Diameter of the Kerr Shadow",
      "published": "2026-01-14 17:44:54+00:00"
    }
  },
  {
    "text": "The resulting expression provides fast evaluations of the shadow size without numerical ray tracing, making it convenient for repeated calls in parameter inference and rapid model comparisons.",
    "metadata": {
      "title": "A Closed-Form Surrogate for the Equivalent Diameter of the Kerr Shadow",
      "published": "2026-01-14 17:44:54+00:00"
    }
  },
  {
    "text": "Tabular Foundation Models (TFMs) have recently shown strong in-context learning capabilities on structured data, achieving zero-shot performance comparable to traditional machine learning methods. We find that zero-shot TFMs already achieve strong performance, while the benefits of fine-tuning are highly model and data-dependent. Meta-learning and PEFT provide moderate gains under specific conditions, whereas full supervised fine-tuning (SFT) often reduces accuracy or calibration quality. This",
    "metadata": {
      "title": "Exploring Fine-Tuning for Tabular Foundation Models",
      "published": "2026-01-14 17:40:46+00:00"
    }
  },
  {
    "text": "whereas full supervised fine-tuning (SFT) often reduces accuracy or calibration quality. This work presents the first comprehensive study of fine-tuning in TFMs across benchmarks including TALENT, OpenML-CC18, and TabZilla. We compare Zero-Shot, Meta-Learning, Supervised (SFT), and parameter-efficient (PEFT) approaches, analyzing how dataset factors such as imbalance, size, and dimensionality affect outcomes. Our findings cover performance, calibration, and fairness, offering practical",
    "metadata": {
      "title": "Exploring Fine-Tuning for Tabular Foundation Models",
      "published": "2026-01-14 17:40:46+00:00"
    }
  },
  {
    "text": "affect outcomes. Our findings cover performance, calibration, and fairness, offering practical guidelines on when fine-tuning is most beneficial and its limitations.",
    "metadata": {
      "title": "Exploring Fine-Tuning for Tabular Foundation Models",
      "published": "2026-01-14 17:40:46+00:00"
    }
  },
  {
    "text": "Word Sense Disambiguation (WSD) has been widely evaluated using the semantic frameworks of WordNet, BabelNet, and the Oxford Dictionary of English. However, for the UCREL Semantic Analysis System (USAS) framework, no open extensive evaluation has been performed beyond lexical coverage or single language evaluation. In this work, we perform the largest semantic tagging evaluation of the rule based system that uses the lexical resources in the USAS framework covering five different languages using",
    "metadata": {
      "title": "Creating a Hybrid Rule and Neural Network Based Semantic Tagger using Silver Standard Data: the PyMUSAS framework for Multilingual Semantic Annotation",
      "published": "2026-01-14 17:31:21+00:00"
    }
  },
  {
    "text": "that uses the lexical resources in the USAS framework covering five different languages using four existing datasets and one novel Chinese dataset. We create a new silver labelled English dataset, to overcome the lack of manually tagged training data, that we train and evaluate various mono and multilingual neural models in both mono and cross-lingual evaluation setups with comparisons to their rule based counterparts, and show how a rule based system can be enhanced with a neural network",
    "metadata": {
      "title": "Creating a Hybrid Rule and Neural Network Based Semantic Tagger using Silver Standard Data: the PyMUSAS framework for Multilingual Semantic Annotation",
      "published": "2026-01-14 17:31:21+00:00"
    }
  },
  {
    "text": "rule based counterparts, and show how a rule based system can be enhanced with a neural network model. The resulting neural network models, including the data they were trained on, the Chinese evaluation dataset, and all of the code have been released as open resources.",
    "metadata": {
      "title": "Creating a Hybrid Rule and Neural Network Based Semantic Tagger using Silver Standard Data: the PyMUSAS framework for Multilingual Semantic Annotation",
      "published": "2026-01-14 17:31:21+00:00"
    }
  },
  {
    "text": "Text-to-image (T2I) models are increasingly popular, producing a large share of AI-generated images online. To compare model quality, voting-based leaderboards have become the standard, relying on anonymized model outputs for fairness. In this work, we show that such anonymity can be easily broken. We find that generations from each T2I model form distinctive clusters in the image embedding space, enabling accurate deanonymization without prompt control or training data. Using 22 models and 280",
    "metadata": {
      "title": "Identifying Models Behind Text-to-Image Leaderboards",
      "published": "2026-01-14 17:30:58+00:00"
    }
  },
  {
    "text": "enabling accurate deanonymization without prompt control or training data. Using 22 models and 280 prompts (150K images), our centroid-based method achieves high accuracy and reveals systematic model-specific signatures. We further introduce a prompt-level distinguishability metric and conduct large-scale analyses showing how certain prompts can lead to near-perfect distinguishability. Our findings expose fundamental security flaws in T2I leaderboards and motivate stronger anonymization",
    "metadata": {
      "title": "Identifying Models Behind Text-to-Image Leaderboards",
      "published": "2026-01-14 17:30:58+00:00"
    }
  },
  {
    "text": "findings expose fundamental security flaws in T2I leaderboards and motivate stronger anonymization defenses.",
    "metadata": {
      "title": "Identifying Models Behind Text-to-Image Leaderboards",
      "published": "2026-01-14 17:30:58+00:00"
    }
  },
  {
    "text": "This paper analyzes and explicitly solves a class of long-term average impulse control problems and a related class of singular control problems. The underlying process is a general one-dimensional diffusion with appropriate boundary behavior. The model is motivated by applications such as the optimal long-term management of renewable resources and financial portfolio management. A large class of admissible policies is identified over which the agent seeks to maximize her long-term average",
    "metadata": {
      "title": "Long-Term Average Impulse and Singular Control of a Growth Model with Two Revenue Sources",
      "published": "2026-01-14 17:30:34+00:00"
    }
  },
  {
    "text": "of admissible policies is identified over which the agent seeks to maximize her long-term average reward, consisting of a running reward and income from either discrete impulses or singular actions. The long-term expected total reward and its relation to overtaking optimality is also considered. Sensitivity analysis with regard to the parameters of the impulse control model are performed. Key connections between the impulse and singular control problems are displayed.",
    "metadata": {
      "title": "Long-Term Average Impulse and Singular Control of a Growth Model with Two Revenue Sources",
      "published": "2026-01-14 17:30:34+00:00"
    }
  },
  {
    "text": "In this article, we prove that if $X$ is a complex manifold of dimension $n\\geq 4$ such that there exists a $q$-convex with corners function $f\\in F_{q}(X)$, then every holomorphic line bundle over $\\{f>c\\}$ extends uniquely to $X$ if $1\\leq q\\leq n-3$. This generalizes a well-known result obtained in \\cite{ref5} for $q$-complete with corners complex manifolds with a corresponding exhaustion function $f \\in F_{q}(X)$, when $n \\geq 3q$.",
    "metadata": {
      "title": "A generalization of Hartog's extension of line bundles",
      "published": "2026-01-14 17:29:49+00:00"
    }
  },
  {
    "text": "Recent studies report a mild discrepancy between baryon acoustic oscillation (BAO) and cosmic microwave background (CMB) measurements within the $\u039b$CDM framework. This discrepancy could be explained if the optical depth $\u03c4$ inferred from the CMB large-scale E-mode polarization is underestimated, which may be biased by foreground-subtraction or instrumental systematics. In this work, we present a determination of $\u03c4$ independent of the large-scale E-mode polarization, using the latest",
    "metadata": {
      "title": "A New Constraint on the Optical Depth from the Reionization History Independent of CMB Large-Scale E-Mode Polarization",
      "published": "2026-01-14 17:28:14+00:00"
    }
  },
  {
    "text": "present a determination of $\u03c4$ independent of the large-scale E-mode polarization, using the latest measurements of the redshift evolution of the neutral hydrogen fraction $x_\\mathrm{HI}(z)$, which is constrained by Lyman-$\u03b1$ forest and damping-wing absorption measurements at $z\\sim5$-$14$, based on ground-based optical and JWST observations. Combining $x_\\mathrm{HI}(z)$ with the Planck CMB power spectra excluding the large-scale E-mode polarization, we obtain $\u03c4=0.0552^{+0.0019}_{-0.0026}$, a",
    "metadata": {
      "title": "A New Constraint on the Optical Depth from the Reionization History Independent of CMB Large-Scale E-Mode Polarization",
      "published": "2026-01-14 17:28:14+00:00"
    }
  },
  {
    "text": "spectra excluding the large-scale E-mode polarization, we obtain $\u03c4=0.0552^{+0.0019}_{-0.0026}$, a stringent constraint consistent with the previous CMB results including the large-scale E-mode. We also evaluate a potential systematic error in our method associated with absorption modeling, obtaining $\u03c4=0.0552^{+0.0075}_{-0.0049}$. Using this constraint on $\u03c4$, we resolve the degeneracy in the $\u03c4$-$\u03a9_m$ plane and find a $2.4\u03c3$ tension with the DESI DR2 BAO results, thereby confirming the",
    "metadata": {
      "title": "A New Constraint on the Optical Depth from the Reionization History Independent of CMB Large-Scale E-Mode Polarization",
      "published": "2026-01-14 17:28:14+00:00"
    }
  },
  {
    "text": "the $\u03c4$-$\u03a9_m$ plane and find a $2.4\u03c3$ tension with the DESI DR2 BAO results, thereby confirming the claimed mild discrepancy suggestive of physics beyond $\u039b$CDM. Finally, we derive an upper limit on the sum of neutrino masses, $\u03a3m_\u03bd<0.0550\\,(0.0717)$ eV at the 95% (99%) confidence level. This limit favors the normal mass ordering and, when combined with the lower limits from neutrino oscillation experiments, yields a further constraint, $\u03a3m_\u03bd=0.0594_{-0.0007}^{+0.0113}$ eV. However, the",
    "metadata": {
      "title": "A New Constraint on the Optical Depth from the Reionization History Independent of CMB Large-Scale E-Mode Polarization",
      "published": "2026-01-14 17:28:14+00:00"
    }
  },
  {
    "text": "experiments, yields a further constraint, $\u03a3m_\u03bd=0.0594_{-0.0007}^{+0.0113}$ eV. However, the cosmological upper limit and the oscillation-based lower limit show a mild $2.2\u03c3$ tension, providing an independent indication of possible physics beyond $\u039b$CDM.",
    "metadata": {
      "title": "A New Constraint on the Optical Depth from the Reionization History Independent of CMB Large-Scale E-Mode Polarization",
      "published": "2026-01-14 17:28:14+00:00"
    }
  },
  {
    "text": "The Addition Theorem for the algebraic entropy of group endomorphisms of torsion abelian groups was proved by Dikranjan, Goldsmith, Salce and Zanardo. It was later extended by Shlossberg to torsion nilpotent groups of class 2. As our main result, we prove the Addition Theorem for endomorphisms of torsion nilpotent groups of arbitrary nilpotency class. As an application, we show that if $G$ is a torsion nilpotent group, then for every $\u03c6\\in \\mathrm{End}(G)$ either the entropy $h(\u03c6)$ is infinite",
    "metadata": {
      "title": "The Addition Theorem for the Algebraic Entropy of Torsion Nilpotent Groups",
      "published": "2026-01-14 17:27:33+00:00"
    }
  },
  {
    "text": "nilpotent group, then for every $\u03c6\\in \\mathrm{End}(G)$ either the entropy $h(\u03c6)$ is infinite or $h(\u03c6)=\\log(\u03b1)$ for some $\u03b1\\in\\mathbb N$. We further obtain, for automorphisms of locally finite groups, the Addition Theorem with respect to all terms of the upper central series; in particular, the Addition Theorem holds for automorphisms of $\u03c9$-hypercentral groups. Finally, we establish a reduction principle: if $\\mathfrak X$ is a variety of locally finite groups, then the Addition Theorem for",
    "metadata": {
      "title": "The Addition Theorem for the Algebraic Entropy of Torsion Nilpotent Groups",
      "published": "2026-01-14 17:27:33+00:00"
    }
  },
  {
    "text": "principle: if $\\mathfrak X$ is a variety of locally finite groups, then the Addition Theorem for endomorphisms holds in $\\mathfrak X$ if and only if it holds for locally finite groups generated by bounded sets.",
    "metadata": {
      "title": "The Addition Theorem for the Algebraic Entropy of Torsion Nilpotent Groups",
      "published": "2026-01-14 17:27:33+00:00"
    }
  },
  {
    "text": "Constrained propagation of massless fields is ubiquitous in physical systems, arising from boundaries, material structure, or other restrictions on admissible modes. This paper shows that such constraints generically induce mass-like terms in the effective dispersion relation, without modifying the underlying field equations or introducing new degrees of freedom. Working at an abstract level, constraints are represented as linear operators acting on the field's mode space. Restriction of the",
    "metadata": {
      "title": "Constraint-Induced Effective Mass in Massless Field Propagation",
      "published": "2026-01-14 17:27:07+00:00"
    }
  },
  {
    "text": "are represented as linear operators acting on the field's mode space. Restriction of the admissible mode manifold produces a spectral gap whose magnitude is set by the smallest non-zero eigenvalue of an associated positive semidefinite operator. This gap may be identified with an effective mass parameter, yielding a Proca-like dispersion relation in the long-wavelength limit. The resulting Mass Induction Principle identifies rank reduction of the accessible mode space as the structural",
    "metadata": {
      "title": "Constraint-Induced Effective Mass in Massless Field Propagation",
      "published": "2026-01-14 17:27:07+00:00"
    }
  },
  {
    "text": "Mass Induction Principle identifies rank reduction of the accessible mode space as the structural mechanism responsible for effective mass generation in constrained massless fields. Familiar systems such as plasmas, superconductors, and periodic media realise this structure as special cases, without introducing new dynamics. The analysis is deliberately dispersion-level and non-phenomenological: it does not assert a field-theoretic mass term, does not address vacuum propagation, and does not",
    "metadata": {
      "title": "Constraint-Induced Effective Mass in Massless Field Propagation",
      "published": "2026-01-14 17:27:07+00:00"
    }
  },
  {
    "text": "it does not assert a field-theoretic mass term, does not address vacuum propagation, and does not make claims about bounds on intrinsic particle masses.",
    "metadata": {
      "title": "Constraint-Induced Effective Mass in Massless Field Propagation",
      "published": "2026-01-14 17:27:07+00:00"
    }
  }
]